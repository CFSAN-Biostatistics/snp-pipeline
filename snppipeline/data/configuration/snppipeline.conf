##############################################################################
# This is a SNP Pipeline configuration file.  
#
# PURPOSE:
# You can use this file to customize the behavior of the SNP Pipeline by 
# passing program options to the tools used within the SNP pipeline.
#
# HOW TO USE:
# 1. Edit this file to specify the program options
# 2. Specify this file with the -c option to run_snp_pipeline.sh
#
# TIPS:
# - You can create a copy of this file with default values by running
#   the command: "copy_snppipeline_data.py configurationFile"
# - You can have more than one configuration file and use different 
#   configurations for different circumstances.
# - This configuration file is executed as a shell script defining 
#   environment variables.  All the normal syntax conventions of shell 
#   scripts apply.
# - Enclose parameters in quotes to prevent shell character expansion.
# - New versions of the SNP pipeline may introduce new configuration 
#   parameters.  Existing config files, like this one, will not be updated
#   automatically with those new parameters, but you can add the new 
#   parameters manually.  
##############################################################################


# Exit the pipeline upon detecting errors affecting individual samples.  The pipeline 
# will always stop upon detecting global errors affecting all samples.
# When this parameter is not set to a value, the pipeline will stop upon detecting 
# individual sample errors.  If you want the pipeline to continue, you must explicitly set
# this parameter false.
SnpPipeline_StopOnSampleError=true

# Set these options to limit the number of processes running concurrently on
# a workstation.  When these parameters are not set to a value, the pipeline
# will launch multiple concurrent processes using all available CPU cores.
# These three parameters are only used by run_snp_pipeline.sh.  These parameters 
# are ignored when running the pipeline with an HPC job queue.
#
# Maximum concurrent prepSamples.sh processes (SAMtools and Varscan)
# Default if not set: all cpu cores
MaxConcurrentPrepSamples=
#
# Maximum concurrent call_consensus.py processes
# Default if not set: all cpu cores
MaxConcurrentCallConsensus=

# Maximum concurrent collectSampleMetrics.sh processes
# Default if not set: all cpu cores
MaxConcurrentCollectSampleMetrics=

# Maximum number of snps allowed for each sample.  Any sample with excessive snps exceeding
# this limit will be excluded from the final snp list and snp matrix.
# Set to -1 to include all samples regardless of number of snps
SnpPipeline_MaxSnps=-1

# Which aligner to use: bowtie2 or smalt
# Default if not set: bowtie2
SnpPipeline_Aligner="bowtie2"

# Parameters passed to the bowtie2 indexer
# Default if not set: none
Bowtie2Build_ExtraParams=""

# Parameters passed to the smalt indexer
# Default if not set: none
SmaltIndex_ExtraParams="-k 20 -s 1"

# Parameters passed to the SAMtools faidx tool
# Default if not set: none
SamtoolsFaidx_ExtraParams=""

# Parameters passed to the bowtie2 aligner
# Defaults:
#   If you do not specify the -p option, it defaults to 8 threads on an HPC or all cpu cores otherwise.
#      There is no way to completely suppress the -p option.
#   If Bowtie2Align_ExtraParams is not set, the "--reorder" option is enabled by default.
#      Any value, even a single space, will suppress the reorder option.
#
# -p        : number of parallel alignment threads
# --reorder : generate output records in the same order as the reads in the input file
# -X        : maximum inter-mate distance (as measured from the furthest extremes of the mates) for valid concordant paired-end alignments
Bowtie2Align_ExtraParams="--reorder -X 1000"

# Parameters passed to the smalt aligner
# Defaults:
#   If you do not specify the -n option, it defaults to 8 threads on an HPC or all cpu cores otherwise.
#      There is no way to completely suppress the -n option.
#   If Bowtie2Align_ExtraParams is not set, the "-O" option is enabled by default.
#      Any value, even a single space, will suppress the -O option.
#
# -n : number of parallel alignment threads
# -O : generate output records in the same order as the reads in the input file
# -i : maximum insert size for paired-end reads
# -r : random number seed, if seed < 0 reads with multiple best mappings are reported as 'not mapped'
# -y : filters output alignments by a threshold in the number of exactly matching nucleotides
SmaltAlign_ExtraParams="-O -i 1000 -r 1"

# Parameters passed to the SAMtools view tool when filtering the SAM file
# Defaults:
#   If SamtoolsSamFilter_ExtraParams is not set, the "-F 4" option is enabled by default.  
#      Any value, even a single space, will suppress the -F option.
#
# -F 4      : discard unmapped reads
SamtoolsSamFilter_ExtraParams="-F 4"

# Parameters passed to the SAMtools sort tool when sorting the BAM file
# Default if not set: none
SamtoolsSort_ExtraParams=""

# Parameters passed to the SAMtools mpileup tool
# Default if not set: none
# -q        : minimum mapping quality for an alignment to be used
# -Q        : minimum base quality for a base to be considered 
# -x        : disable read-pair overlap detection
SamtoolsMpileup_ExtraParams="-q 0 -Q 13"

# Parameters passed to the Varscan mpileup2snp tool
# Default if not set: none
# --min-avg-qual : minimum base quality at a position to count a read
# --min-var-freq : minimum variant allele frequency threshold
VarscanMpileup2snp_ExtraParams="--min-avg-qual 15 --min-var-freq 0.90"

# Parameters passed to the Varscan Java Virtual Machine
# Default if not set: none
# -Xmx3000m  : use 3000 MB memory (modify as needed)
VarscanJvm_ExtraParams=""

# Parameters passed to create_snp_list.py
# Default if not set: none
CreateSnpList_ExtraParams="--maxsnps $SnpPipeline_MaxSnps --verbose 1"

# Parameters passed to call_consensus.py
# Default if not set: none
# --minConsFreq        : Mimimum fraction of reads that must agree to make a 
#                        consensus call
# --minBaseQual        : Mimimum base quality score to count a read.
# --minConsStrdDpth    : Consensus strand depth. Minimum number of high-quality
#                        reads supporting the consensus which must be present
#                        on both the forward and reverse strands to make a call
# --minConsStrdBias    : Minimum fraction of the high-quality consensus-supporting
#                        reads which must be present on both the forward and 
#                        reverse strands to make a call
# --vcfFileName        : VCF Output file name. If specified, a VCF file with
#                        this file name will be created in the same directory
#                        as the consensus fasta file for this sample.
# --vcfAllPos          : Flag to cause VCF file generation at all positions,
#                        not just the snp positions. This has no effect on the
#                        consensus fasta file, it only affects the VCF file.
#                        This capability is intended primarily as a diagnostic
#                        tool and enabling this flag will greatly increase
#                        execution time.
# --vcfPreserveRefCase : Flag to cause the VCF file generator to emit each reference
#                        base in uppercase/lowercase as it appears in the reference
#                        sequence file.  If not specified, the reference base is 
#                        emitted in uppercase.
# --vcfFailedSnpGt     : Controls the VCF file GT data element when a snp fails 
#                        filters.  Possible values:
#                           "." : The GT element will be a dot, indicating unable to make a call (default)
#                           "0" : The GT element will be 0, indicating the reference base
#                           "1" : The GT element will be the ALT index of the most commonly occuring base, usually 1

CallConsensus_ExtraParams="--verbose 1 --minConsFreq 0.6 --vcfFileName consensus.vcf"

# Parameters passed to create_snp_matrix.py
# Default if not set: none
CreateSnpMatrix_ExtraParams="--verbose 1"

# Parameters passed to create_snp_reference_seq.py
# Default if not set: none
CreateSnpReferenceSeq_ExtraParams="--verbose 1"

# Parameters passed to mergeVcf.sh
# Default if not set: none
MergeVcf_ExtraParams=""

# Parameters passed to collectSampleMetrics.sh
# Default if not set: none
CollectSampleMetrics_ExtraParams="-m $SnpPipeline_MaxSnps"

# Parameters passed to combineSampleMetrics.sh
# Default if not set: none
CombineSampleMetrics_ExtraParams=""


##############################################################################
# HPC Configuration Parameters
##############################################################################

# Strip the .suffix from the job id when specifying job array dependencies.
# It may be necessary to change this parameter if qsub fails with an illegal 
# dependency error.
Torque_StripJobArraySuffix=false
GridEngine_StripJobArraySuffix=true

# For use with Grid Engine, it is necessary to specify a "parallel environment"
# at CFSAN, the designated environment is called "mpi"  Its key value is "pe_slots".
GridEngine_PEname="mpi"

# Extra parameters passed to qsub.
# Default if not set: none
GridEngine_QsubExtraParams=""
Torque_QsubExtraParams=""
